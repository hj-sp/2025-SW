{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HH-S2iOP7zg"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "max_retries = 5\n",
        "retry_delay = 3\n",
        "\n",
        "for attempt in range(max_retries):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "                {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        print(response.choices[0].message.content)\n",
        "        break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] API 오류 발생: {e}\")\n",
        "\n",
        "        if attempt < max_retries - 1:\n",
        "            print(f\"{retry_delay}초 후 재시도...\")\n",
        "            time.sleep(retry_delay)\n",
        "        else:\n",
        "            print(\"최대 재시도 횟수 초과. 요청을 종료합니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=texts\n",
        "    )\n",
        "\n",
        "\n",
        "    return [item.embedding for item in response.data]\n",
        "\n",
        "\n",
        "\n",
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\", \"violet\", \"cyan\", \"black\", \"white\"]\n",
        "\n",
        "\n",
        "color_embeddings = get_embeddings(color_words)\n",
        "\n",
        "\n",
        "for word, embedding in zip(color_words, color_embeddings):\n",
        "    print(f\"{word}: {embedding[:5]} ...\")   # 앞 5개만 표시\n",
        "    print(f\"Embedding dimension: {len(embedding)}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ybqRBjbmQdTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "response = client.files.create(\n",
        "    file=open(\"mydata.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "file_id = response.id\n",
        "\n",
        "response = client.fine_tuning.jobs.create(\n",
        "    training_file=file_id,\n",
        "    model=\"gpt-4o-mini\"\n",
        ")\n",
        "fine_tune_id = response.id\n",
        "\n",
        "while True:\n",
        "    job = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "    status = job.status\n",
        "    print(status)\n",
        "    if status in [\"succeeded\", \"failed\"]:\n",
        "        break\n",
        "    time.sleep(60)\n",
        "\n",
        "if status == \"succeeded\":\n",
        "    ft_model = job.fine_tuned_model\n",
        "    result = client.chat.completions.create(\n",
        "        model=ft_model,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Translate the following English text to French: Good night\"}\n",
        "        ],\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(result.choices[0].message.content)\n",
        "else:\n",
        "    print(\"fine-tuning failed\")\n"
      ],
      "metadata": {
        "id": "z4W68zI0oXcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "def edit_text(input_text, instruction):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that edits text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Text: {input_text}\\nInstruction: {instruction}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(edited_text)\n"
      ],
      "metadata": {
        "id": "wqp54dN9tXE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "def moderate_text(input_text):\n",
        "    response = client.moderations.create(\n",
        "        model=\"omni-moderation-latest\",\n",
        "        input=input_text\n",
        "    )\n",
        "    return response\n",
        "\n",
        "input_texts = [\n",
        "    \"I want to harm myself.\",\n",
        "    \"You are an amazing person!\",\n",
        "    \"Let's meet at 8 PM.\",\n",
        "    \"I hate you and I want to hurt you.\"\n",
        "]\n",
        "\n",
        "for text in input_texts:\n",
        "    result = moderate_text(text)\n",
        "    print(text)\n",
        "    print(result)\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "ls8X3YPMr1vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "def generate_image(prompt):\n",
        "    response = client.images.generate(\n",
        "        model=\"gpt-image-1\",\n",
        "        prompt=prompt,\n",
        "        size=\"1024x1024\",\n",
        "        n=1\n",
        "    )\n",
        "    image_url = response.data[0].url\n",
        "    return image_url\n",
        "\n",
        "def save_image(image_url, filename):\n",
        "    res = requests.get(image_url)\n",
        "    img = Image.open(BytesIO(res.content))\n",
        "    img.save(filename)\n",
        "\n",
        "prompt = \"A futuristic cityscape at sunset\"\n",
        "\n",
        "image_url = generate_image(prompt)\n",
        "print(image_url)\n",
        "\n",
        "save_image(image_url, \"generated_image.png\")\n"
      ],
      "metadata": {
        "id": "yFbtnKXLr4av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"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\"\n",
        ")\n",
        "\n",
        "def generate_code(prompt, model=\"gpt-4.1-mini\", max_tokens=1000):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You generate only code without explanations.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0\n",
        "        )\n",
        "        code = response.choices[0].message.content.strip()\n",
        "        return code\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "prompt = \"Write a C code that computes Fibonacci number using memoization.\"\n",
        "\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "if generated_code:\n",
        "    print(generated_code)\n",
        "else:\n",
        "    print(\"Failed to generate code.\")\n"
      ],
      "metadata": {
        "id": "NdLRJEbHsYpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
        "\n",
        "upload_response = client.files.create(\n",
        "    file=open(\"king-style-chat.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "print(upload_response)\n",
        "\n",
        "list_response = client.files.list()\n",
        "print(list_response)\n",
        "\n",
        "file_id = upload_response.id\n",
        "retrieve_response = client.files.retrieve(file_id)\n",
        "print(retrieve_response)\n",
        "\n",
        "delete_response = client.files.delete(file_id)\n",
        "print(delete_response)\n"
      ],
      "metadata": {
        "id": "jQt2Vm55ssYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"YOUR_API_KEY_HERE\")\n",
        "\n",
        "def transcribe_audio(file_path, model=\"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        response = client.audio.transcriptions.create(\n",
        "            model=model,\n",
        "            file=f,\n",
        "            response_format=response_format,\n",
        "            temperature=temperature,\n",
        "            language=language,\n",
        "            prompt=prompt\n",
        "        )\n",
        "    return response\n",
        "\n",
        "file_path = \"Dracula.mp3\"\n",
        "\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(transcription)\n"
      ],
      "metadata": {
        "id": "te78YDV_sy6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}